<!DOCTYPE html>
<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">

<!-- Start of Practical boilerplate. -->
<link rel="stylesheet" type="text/css" href="ICA%20Practical_files/fsl.css">
<link rel="stylesheet" type="text/css" href="ICA%20Practical_files/quiz.css">
<link rel="stylesheet" type="text/css" href="ICA%20Practical_files/viz.css">

<script type="text/javascript" src="ICA%20Practical_files/quiz.js"></script>
<script type="text/javascript" src="ICA%20Practical_files/showhide.js"></script>
<script type="text/javascript" src="ICA%20Practical_files/viz.js"></script>
<script type="text/javascript">
window.onload=function() {
    setupQuizQuestions();
    var graphs = document.querySelectorAll(".viz-graph");
    var parser = new DOMParser;
    for (var i = 0; i < graphs.length; i++){
        var div = graphs[i];
        var dom = parser.parseFromString(div.innerHTML, "text/html");
        div.innerHTML = Viz(dom.body.textContent);
        var svg = div.querySelector("svg");
        svg.setAttribute("width",  "100%");
    }
}
</script>
<!-- End of Practical boilerplate. -->


<title>Linked ICA in HCP500</title>
</head>

<body>
<div id="practical">
<h1 class="centred">Linked ICA in HCP500</h1>


<p>This document describes the processing performed in the data from the HCP500 sample as presented in the article
  <b>"Inter-individual differences in human brain structure and morphometry link to variation in demographics and behavior"</b> (under review by elife).
  In the article we perform a multi-modal simultaneous factorization of several structural brain features using the Linked-ICA model introduced in Groves et al. 2011.
  After the multi-modal factorization we performed linear correlations using each subject contribution to each component and the  behavioral and demographics measures availabke in the HCP sample. </br>
  Here we provide details and code to extract each feature starting from the publicaly available HCP500 sample (operation (A)), perform the Linked-ICA factorization (operation (B)),
  perform the correlations to behavioural measures (operation (C)) available also form the HCP consortium, and perform statistics (operations (D) and (E)). </br>
  For any questions on this document or the process in general please
  contact Alberto Llera in the email address  a.llera at donders.ru.nl
  <br>    
<p> 
<img src="./images/Figure1.tif" alt="Figure 1" width="400" class="center">

<hr>
<h3><a name="dim"> A) Feature extraction: indiviual features processing </a></h3>
The subject-wise  extraction of the set of structural features used as input to the Linked-ICA factorization requires the use of different neuroimaging toolboxes,
i.e. FSL, SPM and freesurfer.<br> 

<ul>
  <li> To analyse the DWI data we used the <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/TBSS/UserGuide"> FSL - TBSS pipeline </a> to extract FA, MD and  MO. The TBSS pipeline as we used it
    here reduces to a few commands that we summarize below.<br>
    <ol>
      <li> run dtifit for each subject.
	<ul>
	  <li>  dtifit -k $HCP_500_DIR/$subj/T1w/Diffusion/data.nii.gz -o $SAVE_DIR/$subj/ -m $HCP_500_DIR/$subj/T1w/Diffusion/nodif_brain_mask.nii.gz
	    -r $HCP_500_DIR/$subj/T1w/Diffusion/bvecs -b $HCP_500_DIR/$subj/T1w/Diffusion/bvals
	</ul>

      <li> Folow the instructions at <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/TBSS/UserGuide"> FSL - TBSS pipeline </a> and process FA images
	<ul>
	  <li> tbss_1_preproc *.nii.gz
	  <li> tbss_2_reg.sh -T
	  <li> tbss_3_postreg -T
	  <li> tbss_4_prestats 0.2
	</ul>
      <li> Follow the instructions and compute MD and MO.
    </ol>
	  
  <li> We used the <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all"> freesurfer recon-all pipeline </a>  - to extract cortical thickness (CT) and pial area (PA). For each subject we used the T1 available at $HCP_500_DIR/$subj/T1w/T1w_acpc_dc_restore.nii.gz
    <ol>
      <li> mkdir $SAVE_DIR/$subj/
      <li> cp $HCP_500_DIR/$subj/T1w/T1w_acpc_dc_restore.nii.gz $SAVE_DIR/$subj/${subj}_T1w_acpc_dc_restore.nii.gz
      <li> mri_convert $SUBJECTS_DIR/$subj/*.nii.gz $SUBJECTS_DIR/$subj/001.mgz
      <li> recon-all -all -qcache -subjid $subj -sd $SUBJECTS_DIR 
	
    </ol>
  <li> We used the same T1s as in the previous step and use the <a href="http://dbm.neuro.uni-jena.de/cat/"> CAT-VBM pipeline </a> to extract gray matter densities using Voxel Based Morphometry (VBM).
  <li>  Finally, the determinants of the deformation fields to commone space (JD) are directly available for each subject at HCP sample in $HCP_500_DIR/$subj/MNINonLinear/xfms/NonlinearRegJacobians.nii.gz.
</ul>

<h3><a name="dim"> Subjects feature grouping </a></h3>
  For each feature, subject-wise images need to be concatenated by adding a new dimension to the images that will enconde the subject index.<br> 

<ul>
  <li>For features encoded as 3-d NIfTI images (VDB, FA, MD, MO, JD), the concatenation into 4-d images is done using <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Fslutils"> fslmerge </a>. 
      <li> For features encoded as 2-D .MGH images (CT and PA), the concatenation into 3-d images is done using <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/mri_concat"> mri_concat </a>.  

</ul>
<h3><a name="dim"> Spatial smooting  </a></h3>
For computational reasons spatial smooting is adviced [Groves et al. 2011].<br>
In the present work we used isotropic smoothing and it was achieved using  <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT"> flirt </a>.  

<ul>
  <li> FA, MD, and MO was downsampled at 2mm isotropic.
  <li> VBM was downsampled at 4mm isotropic.
  <li> JD was kept at 2mm isotropic.  
  <li> PA and CT was keep in fsaverage space.   
</ul>


<hr>
<h3><a name="dim">B) Linked-ICA </a></h3>
</p> <b>Linked ICA</b> is the tool in <b>FSL</b> that simultaneously decomposes multiple MRI data
sets into subject-courses and spatial maps using Bayesian Independent Component Analysis (ICA). <br>
<ol>
  <li> You can find the matlab code with some extra aditional necessary tools in the downloaded folder ./matlab_flica_toolbox
     <ul>
      <li> A matlab script to reproduce the main factorization can be found <a href="./scripts/matlab_Linked_ICA_HCP500.m"> here. </a>
      <li> The original matlab code implementing the Linked ICA factorization can also be found at the fsl page <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLICA"> flica_matlab.
    </ul>

   
  <li> Python code implementing the Linked ICA factorization will be available upon publication at <a href="https://github.com/allera"> flica_python. </a>
    <ul>
      <li> A python script to reproduce the main factorization can be found <a href="python_Linked_ICA_HCP500.html"> here. </a>
    </ul>

</ol>
</p>
</ul>
<h3><a name="dim"> The Linked ICA output  </a></h3>
The output of the Linked ICA factorization is storaged in a folder where we can find: .<br>

<ul>
  <li> Spatial maps at each component: storaged for each input feature type as .nii.gz or .mgh files
  <li> Subject loadings to components  are storaged as SubjectsCoursesOut.txt
  <li> Feature contributions to components are visualized at PCbars.png     
</ul>


<hr>
<h3><a name="dim">(C) Post-hoc correlations to behavior </a></h3>
<p> We perform linear correlations between the subject loadings (SubjectsCoursesOut.txt) and each behavioral measure availabel in the HCP sample.</p>


<hr>
<h3><a name="dim">(D) Permutation Statistics </a></h3>
<p> We compute statistics using over each of the observed correlation values using 
  <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/PALM"> PALM. </a> 
</p>

<hr>
<h3><a name="dim">(E) Correction for multiple comparisons </a></h3>
<p> We use FDR correction using the matlab code at 
  <a href="https://nl.mathworks.com/matlabcentral/fileexchange/27418-fdr_bh"> [Benjamini et al. 1995]. </a> 
</p>

<hr>
<h3><a name="dim"> Visualization of spatial maps </a></h3>
<p> To visualize the NIfTI spatial maps we use  
  <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslView"> fslview </a>, and for the .mgh files we used
  <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/FreeviewGuide"> freeview </a>. 
</p>

</div>


</body></html>
